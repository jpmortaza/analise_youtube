{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpmortaza/analise_youtube/blob/main/Pandorga_tech_%3Eyoutube_legendas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgYhlFDq9PrF"
      },
      "source": [
        "# PANDORGA TECH - EXTRAÇÃO E ANALISE TEXTUAL DE VÍDEO DO YOUTUBE (LEGENDA DO YOUTUBE)\n",
        "Esse script Sugiu da necessidade de realizar a analise semantica de diversos vídeos do youtube, precisavamos criar um relatório com as pautas mais abordadas por um candidato em seus vídeos, o interessante é que ele tinha mais de mil vídeos no youtube, o que seria impossível de ser realizado manualmente ou seja assistindo os vídeos.\n",
        "\n",
        "Instruções de utilização.\n",
        "1. Na barra da esquerda clique no icone arquivos.\n",
        "2. Abra o arquivo de txt id_youtube.\n",
        "3. Insira nele os links dos vídeos ou apenas um link que quer analisar. (vídeos que contenham legenda)\n",
        "4. Execute IMPORT/INSTALL.\n",
        "5. Execute o EXTRAIR LEGENDAS.\n",
        "6. Abra o DATAFRAME/DOWNLOAD.\n",
        "7. Execute o #Criar DataFrame\n",
        "8. Escolha se quer fazer download ou quer analisar os textos extraídos.\n",
        "9. O arquivo com os textos será salvo em arquivos, na barra da esquereda com o nome de dados.csv - poderá fazer download desse arquivo.\n",
        "10. Em ANALISE TEXTUAL possível fazer:\n",
        "- Contagem de palavras.\n",
        "- Núvem de palavras.\n",
        "\n",
        "Assista o vídeo abaixo:\n",
        "[Vídeo Youtube](https://www.youtube.com/watch?v=42n878GWZeE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycf29wnsubNs"
      },
      "source": [
        "# IMPORT/INSTALL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExsRYjLAt6Bp",
        "outputId": "e51d1e9d-d0be-4718-bde5-81dbe06731a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.7/dist-packages (0.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from youtube-transcript-api) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->youtube-transcript-api) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->youtube-transcript-api) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->youtube-transcript-api) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->youtube-transcript-api) (2021.10.8)\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.7/dist-packages (12.0.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "!pip install youtube-transcript-api\n",
        "!pip install pytube\n",
        "!pip install wordcloud -q\n",
        "\n",
        "from pytube import extract\n",
        "import pandas as pd\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuTSVzqtw_6T"
      },
      "source": [
        "# EXTRAI LEGENDAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vptZdh3BBqOd"
      },
      "outputs": [],
      "source": [
        "#EXTRAI AS LEGENDAS\n",
        "with open(\"id_youtube.txt\") as file:\n",
        "    for link in file:\n",
        "        id=extract.video_id(link)\n",
        "        srt = YouTubeTranscriptApi.get_transcript(id,languages=['pt'])\n",
        "#        with open(\"transcricao.txt\", \"a\") as f:\n",
        "#            for i in srt:\n",
        "#                f.write(\"{}\\n\".format(i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXPZVwZuxGXl"
      },
      "source": [
        "# DATAFRAME/DOWNLOAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9Gi0iT21rlRH"
      },
      "outputs": [],
      "source": [
        "#CRIAR O DATAFRAME\n",
        "df = pd.DataFrame(srt)\n",
        "n_df=df.assign(Video=id)\n",
        "char = [\"\\n\",\"!\",\"?\",\".\",\",\"]\n",
        "for symbol in char:\n",
        "    df['text'] = df['text'].str.replace(symbol, \" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xK_HQkbptWzf"
      },
      "outputs": [],
      "source": [
        "#DOWNLOAD EM CSV\n",
        "df.to_csv(\"dados.csv\", encoding = 'utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3Y9ZzEhvRHS"
      },
      "outputs": [],
      "source": [
        "#VER O DATAFRAME\n",
        "n_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z-KaBW5xPOj"
      },
      "source": [
        "# ANALISE TEXTUAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5091qpsbspK2",
        "outputId": "b9b1645f-979f-4573-f5aa-42593cd4fd37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantidade de Palavras: 88264\n"
          ]
        }
      ],
      "source": [
        "#CONTAGEM DE PALAVRAS\n",
        "palavras = \" \".join(s for s in df['text'])\n",
        "print(\"Quantidade de Palavras: {}\".format(len(palavras)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E961HsVysuYG"
      },
      "outputs": [],
      "source": [
        "#NOVO MÓDULO PARA NÚVEM DE PALAVRAS\n",
        "stopwords.extend([\"né\",\"aí\",\"aqui\",\"agora\",\"vou\",\n",
        "                  \"quer\",\"vai\",\"porque\",\"lá\",\"tá\",\"olha\",\"então\"])\n",
        "\n",
        "wordcloud = WordCloud(stopwords=stopwords,\n",
        "                      background_color=\"white\",\n",
        "                      width=1600, height=800).generate(palavras)\n",
        "# mostrar a imagem final\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "ax.imshow(wordcloud, interpolation='bilinear')\n",
        "ax.set_axis_off()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3pZ_pSZ3eS8"
      },
      "outputs": [],
      "source": [
        "print(palavras)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ycf29wnsubNs"
      ],
      "name": "Pandorga_tech->youtube_legendas.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNqOg0TWGxBju+n7OZw4ciZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}